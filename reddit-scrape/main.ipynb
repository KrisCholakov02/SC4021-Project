{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SC4021 - Data Collection, Cleaning and Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "997efd316f30bb09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reddit Data Collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb85f2de43f864e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import praw  # Python Reddit API Wrapper\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.347269Z",
     "start_time": "2024-04-02T13:00:45.007886Z"
    }
   },
   "id": "d0dc2296ee867cd4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the constants and the Reddit instance\n",
    "\n",
    "# Create a Reddit instance\n",
    "reddit = praw.Reddit(user_agent=True, client_id='kqB2Mfaq32Jax9LAmdsr3A',\n",
    "                     client_secret='7HR4TNjSVDXZrgEwlsrjF0Pcwzdc2w', username='KrisCholakov',\n",
    "                     password='kyhnoh-pixci0-Bedgit')\n",
    "\n",
    "# Define the columns for the submissions and comments dataframes\n",
    "submission_columns = [\"author\", \"created_utc\", \"distinguished\", \"id\", \"name\", \"num_comments\", \"score\", \"selftext\", \"title\", \"upvote_ratio\", \"url\"]\n",
    "comment_columns = [\"author\", \"body\", \"body_html\", \"created_utc\", \"distinguished\", \"id\", \"link_id\", \"parent_id\", \"score\"]\n",
    "\n",
    "# Define the directory to save the data for the subreddits\n",
    "data_directory = \"subreddits\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.352585Z",
     "start_time": "2024-04-02T13:00:45.348752Z"
    }
   },
   "id": "f6655cc5a35558dc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the functions to craw the data from Reddit\n",
    "\n",
    "# Function to get the submissions and the corresponding comments for a subreddit\n",
    "def get_submissions_and_comments(reddit, subreddit_name, limit=None):\n",
    "    # Create the lists to store the submissions and comments\n",
    "    submissions_list = []\n",
    "    comments_list = []\n",
    "    \n",
    "    # Define the counter for the submissions and comments\n",
    "    submission_cnt, comment_cnt = 1, 1\n",
    "    \n",
    "    # Browse the submissions\n",
    "    for submission in reddit.subreddit(subreddit_name).top(limit=limit):\n",
    "        # Print the progress - submission title, submission cnt\n",
    "        print(f'{subreddit_name}-{submission_cnt}', submission.title)\n",
    "        # Define the submission\n",
    "        new_submission = {\n",
    "        \"author\": submission.author,\n",
    "        \"created_utc\": submission.created_utc,\n",
    "        \"distinguished\": submission.distinguished,\n",
    "        \"id\": submission.id,\n",
    "        \"name\": submission.name,\n",
    "        \"num_comments\": submission.num_comments,\n",
    "        \"score\": submission.score,\n",
    "        \"selftext\": submission.selftext,\n",
    "        \"title\": submission.title,\n",
    "        \"upvote_ratio\": submission.upvote_ratio,\n",
    "        \"url\": submission.url\n",
    "    }\n",
    "        # Add the submission to the list\n",
    "        submissions_list.append(new_submission)\n",
    "        # Get the comments\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        # Browse the comments\n",
    "        for comment in submission.comments.list():\n",
    "            # Print the progress - comment cnt\n",
    "            print(f'comment #{comment_cnt}')\n",
    "            # Define the comment\n",
    "            new_comment = {\n",
    "            \"author\": comment.author,\n",
    "            \"body\": comment.body,\n",
    "            \"body_html\": comment.body_html,\n",
    "            \"created_utc\": comment.created_utc,\n",
    "            \"distinguished\": comment.distinguished,\n",
    "            \"id\": comment.id,\n",
    "            \"link_id\": comment.link_id,\n",
    "            \"parent_id\": comment.parent_id,\n",
    "            \"score\": comment.score\n",
    "        }\n",
    "            # Add the comment to the list\n",
    "            comments_list.append(new_comment)\n",
    "            comment_cnt += 1\n",
    "        submission_cnt += 1\n",
    "\n",
    "    # Convert the lists to dataframes\n",
    "    submissions = pd.DataFrame(submissions_list, columns=submission_columns)\n",
    "    comments = pd.DataFrame(comments_list, columns=comment_columns)\n",
    "    \n",
    "    return submissions, comments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.357818Z",
     "start_time": "2024-04-02T13:00:45.353428Z"
    }
   },
   "id": "788cbe83f2f92dd8",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the functions to save the data to csv files in the corresponding directory\n",
    "\n",
    "# Function to save the submissions and comments to csv files\n",
    "def save_submissions_and_comments(submissions, comments, subreddit_name):\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(f'{data_directory}/{subreddit_name}'):\n",
    "        os.makedirs(f'{data_directory}/{subreddit_name}')\n",
    "    \n",
    "    # Save the submissions to a csv file\n",
    "    submissions.to_csv(f'{data_directory}/{subreddit_name}/submissions.csv', index=False)\n",
    "    # Save the comments to a csv file\n",
    "    comments.to_csv(f'{data_directory}/{subreddit_name}/comments.csv', index=False)\n",
    "    \n",
    "# Function to check if the subreddit directory exists and if the data is already collected\n",
    "def check_subreddit_data(subreddit_name):\n",
    "    # Check if the subreddit directory exists\n",
    "    if not os.path.exists(f'{data_directory}/{subreddit_name}'):\n",
    "        return False\n",
    "    # Check if the submissions and comments csv files exist\n",
    "    if not os.path.exists(f'{data_directory}/{subreddit_name}/submissions.csv') or not os.path.exists(f'{data_directory}/{subreddit_name}/comments.csv'):\n",
    "        return False\n",
    "    \n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.362619Z",
     "start_time": "2024-04-02T13:00:45.359805Z"
    }
   },
   "id": "d22bab52ee1b672e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the subreddits to crawl the data from\n",
    "subreddits = [\"VisionPro\", \"virtualreality\", \"augmentedreality\", \"MetaQuestVR\", \"oculus\", \"OculusQuest\"]\n",
    "\n",
    "# Crawl the data for the subreddits\n",
    "for subreddit_name in subreddits:\n",
    "    # Check if the data is already collected\n",
    "    if check_subreddit_data(subreddit_name):\n",
    "        continue\n",
    "    # Get the submissions and comments\n",
    "    submissions, comments = get_submissions_and_comments(reddit, subreddit_name, limit=1000)\n",
    "    # Save the data to csv files\n",
    "    save_submissions_and_comments(submissions, comments, subreddit_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.366063Z",
     "start_time": "2024-04-02T13:00:45.363435Z"
    }
   },
   "id": "dd8fb19bb303aca1",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyzing the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ffcf332f1059ee1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.555196Z",
     "start_time": "2024-04-02T13:00:45.366731Z"
    }
   },
   "id": "5164bc4c4a6928e8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the functions to load the data and analyze it\n",
    "\n",
    "# Function to load the submissions and comments dataframes\n",
    "def load_submissions_and_comments(subreddit_name):\n",
    "    # Load the submissions and comments dataframes\n",
    "    submissions = pd.read_csv(f'{data_directory}/{subreddit_name}/submissions.csv')\n",
    "    comments = pd.read_csv(f'{data_directory}/{subreddit_name}/comments.csv')\n",
    "    \n",
    "    return submissions, comments\n",
    "\n",
    "def simple_analyze_submissions_and_comments(submissions, comments):\n",
    "    # Create a dictionary to store the results\n",
    "    results = {}\n",
    "\n",
    "    # Calculate and store the results in the dictionary\n",
    "    results[\"Number of submissions\"] = len(submissions)\n",
    "    results[\"Number of comments\"] = len(comments)\n",
    "    results[\"Number of unique authors in submissions\"] = len(submissions[\"author\"].unique())\n",
    "    results[\"Number of unique authors in comments\"] = len(comments[\"author\"].unique())\n",
    "    results[\"Number of unique submissions\"] = len(submissions[\"id\"].unique())\n",
    "    results[\"Number of unique comments\"] = len(comments[\"id\"].unique())\n",
    "    comments[\"word_length\"] = comments[\"body\"].apply(lambda x: len(str(x).split()))\n",
    "    results[\"Average word length of comments\"] = comments[\"word_length\"].mean()\n",
    "    results[\"Number of comments that have more than 50 words\"] = len(comments[comments[\"word_length\"] > 50])\n",
    "    results[\"Number of submissions that have more than 50 words in the selftext\"] = len(submissions[submissions[\"selftext\"].apply(lambda x: len(str(x).split())) > 50])\n",
    "    results[\"Average score of submissions\"] = submissions[\"score\"].mean()\n",
    "    results[\"Average score of comments\"] = comments[\"score\"].mean()\n",
    "    results[\"Average number of comments per submission\"] = submissions[\"num_comments\"].mean()\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    results = pd.DataFrame(list(results.items()), columns=['Description', 'Data'])\n",
    "    \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:45.559413Z",
     "start_time": "2024-04-02T13:00:45.555866Z"
    }
   },
   "id": "a3d63d55dce97988",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Description           Data\n0                               Number of submissions    5990.000000\n1                                  Number of comments  635630.000000\n2             Number of unique authors in submissions    3875.000000\n3                Number of unique authors in comments  120496.000000\n4                        Number of unique submissions    5990.000000\n5                           Number of unique comments  635629.000000\n6                     Average word length of comments      28.200571\n7     Number of comments that have more than 50 words   91634.000000\n8   Number of submissions that have more than 50 w...     752.000000\n9                        Average score of submissions    1068.839232\n10                          Average score of comments       7.771816\n11          Average number of comments per submission     117.460100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Number of submissions</td>\n      <td>5990.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Number of comments</td>\n      <td>635630.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Number of unique authors in submissions</td>\n      <td>3875.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Number of unique authors in comments</td>\n      <td>120496.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Number of unique submissions</td>\n      <td>5990.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Number of unique comments</td>\n      <td>635629.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Average word length of comments</td>\n      <td>28.200571</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Number of comments that have more than 50 words</td>\n      <td>91634.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Number of submissions that have more than 50 w...</td>\n      <td>752.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Average score of submissions</td>\n      <td>1068.839232</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Average score of comments</td>\n      <td>7.771816</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Average number of comments per submission</td>\n      <td>117.460100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform analysis on the combined data for all subreddits\n",
    "\n",
    "# Load the data for the subreddits and analyze it\n",
    "submissions_list = []\n",
    "comments_list = []\n",
    "for subreddit_name in subreddits:\n",
    "    # Load the submissions and comments dataframes\n",
    "    submissions, comments = load_submissions_and_comments(subreddit_name)\n",
    "    # Add the subreddit name to the submissions and comments dataframes\n",
    "    submissions[\"subreddit\"] = subreddit_name\n",
    "    comments[\"subreddit\"] = subreddit_name\n",
    "    # Add the submissions and comments to the lists\n",
    "    submissions_list.append(submissions)\n",
    "    comments_list.append(comments)\n",
    "\n",
    "# Concatenate the submissions and comments dataframes\n",
    "all_submissions = pd.concat(submissions_list)\n",
    "all_comments = pd.concat(comments_list)\n",
    "\n",
    "# Simple analyze the data\n",
    "simple_analyze_submissions_and_comments(all_submissions, all_comments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:49.349927Z",
     "start_time": "2024-04-02T13:00:45.560146Z"
    }
   },
   "id": "f0d1fe3332fa8713",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "author\nOXIOXIOXI            1789\nTheknyt              1224\nSvenViking           1179\nJorgTheElder         1032\nILoveRegenHealth      753\n                     ... \nOk_Pipe9153             1\nNotDominusGhaul         1\niamnotshook             1\nBryanwithaYnotanI       1\nRaj3d                   1\nName: count, Length: 120495, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the users with most comments\n",
    "all_comments[\"author\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:49.410627Z",
     "start_time": "2024-04-02T13:00:49.350797Z"
    }
   },
   "id": "9b4d0df42f422150",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "author\nAR_MR_XR            57\nacetylan            36\nAugmentedThinker    33\nSpatialComputing    32\nMalkmus1979         32\n                    ..\npampas93             1\nlenanena             1\nfx_mania             1\njbroadway            1\nRollertoaster7       1\nName: count, Length: 3874, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the users with most submissions\n",
    "all_submissions[\"author\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:49.417269Z",
     "start_time": "2024-04-02T13:00:49.413238Z"
    }
   },
   "id": "1adebfa8909323de",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "body\n[изтрито]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        13809\n[премахнато]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2056\nYes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                531\nThanks!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            438\nF                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  371\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ...  \nI haven't done mixed-reality recording myself, so I'm uncertain of the specifics. I can't offer advice from actual experience, but here's a couple of things I did find...\\n\\nIt seems like SteamVR Unity might always have support for this enabled, provided you set it up, according to this: https://steamcommunity.com/app/358720/discussions/0/405694031549662100/\\n\\nMore in-line with what you're talking about: Reading about the above \"external camera\" support, with it changing the \"companion screen\" (monitor output) to be from this other perspective... it seems like the Valheim VR-mod should be able to do something similar with the existing 3rd-person view. Maybe it does have support for this hidden somewhere? Or otherwise could be suggested to the devs.\\n\\nNext is something slick I hadn't seen before, but with the need for additional products, and I don't know if a Unity plugin is sufficient or you'd need access to the sourcecode (of Valheim). They're selling a depth-camera to do this, but they use the depth-capture to apply lighting to you corresponding to in-game lighting: https://www.stereolabs.com/blog/how-to-make-mixed-reality-vr-videos-in-unity/        1\nAlright.  Well I appreciate you weighing in.  Maybe I'll try again and see what I get.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\nDon't forget it's just the external case, not the working parts of the PS3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\nTomato tomahto.  \\n... and you need a 5g router \\[if you're on a Quest\\]... 2.4 will run like ass no matter what you do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\nHi Pot! Or is it Kettle?  Anyway, nice to see you again. 😂                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\nName: count, Length: 596326, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the most common comments\n",
    "all_comments[\"body\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:49.712610Z",
     "start_time": "2024-04-02T13:00:49.418211Z"
    }
   },
   "id": "2ca56ae07462a818",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "body\nOur automod detected strong language being used. Please consider rewriting your comment to something more polite. If this is an error, please don't hesitate to reach out to us.\\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/oculus) if you have any questions or concerns.*                                                                                                                 89\n#I no longer allow Reddit to profit from my content - Mass exodus 2023 -- mass edited with https://redact.dev/                                                                                                                                                                                                                                                                                                                                                                          81\nHey there!  \\nI am so excited to tell you that the game is finally released on SideQuest and is available NOW!\\n\\nLink: [https://sidequestvr.com/app/2109/the-final-overs-early-access](https://sidequestvr.com/app/2109/the-final-overs-early-access)\\n\\nTrailer: [https://www.youtube.com/watch?v=9plM1DgxdOI](https://www.youtube.com/watch?v=9plM1DgxdOI)                                                                                                                           76\nFinally the steam page is up so add to your Wishlist\\n\\n[https://store.steampowered.com/app/1324410/Car\\_Parking\\_Simulator\\_VR/](https://store.steampowered.com/app/1324410/Car_Parking_Simulator_VR/)                                                                                                                                                                                                                                                                                 32\nYo! Coming back to old threads to tell people that the game is out!  \\n\\-->[Steam+Oculus Links here](https://beersandboomerangs.com/).<--  \\nThere's also a free demo in case you just want to check it out :)                                                                                                                                                                                                                                                                          26\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ..\nAfaik it's not completely clear but some studies show that it could have an effect on the coordination strategy / abilities because it's not fully developed yet. When I said children I literally meant children. Teenagers are fine imo\\nEdit: To be clear I don't have anything against letting your young child play VR for a bit with your headset but giving them their own headset and letting them do what they want with it without regulating it is just irresponsible imo     2\n> Not to mention it's what everyone is buying right now so the wait list is gonna be stupid long.\\n\\nwell some site says it should be shipped around end of november...\\n\\ndon't know but the index is not really getting me...maybe the shape of the controllers, (don't want no touch pad like the vive), not to mention google says that the index costs 1079, euros, that seems stupidly pricey compared to the g2 price                                                             2\nThe Quest Pro is designed with an open peripheral view (compared to Quest 2 which blocks as much of the outside world as possible). This is intentional to make the headset’s passthrough mode feel more natural (since the real world in your periphery matches up with the passthrough view in the center of your vision.                                                                                                                                                              2\nBeep. Boop. I'm a robot.\\nHere's a copy of \\n\\n###[1984](https://snewd.com/ebooks/1984-george-orwell/)\\n\\nWas I a good bot? | [info](https://www.reddit.com/user/Reddit-Book-Bot/) | [More Books](https://old.reddit.com/user/Reddit-Book-Bot/comments/i15x1d/full_list_of_books_and_commands/)                                                                                                                                                                                          2\nI use my Quest 1 maybe 4 nights a week and it still always goes for 2-2.5 hours minimum (unless I'm casting or have party chat on the whole time).\\n\\nI got it I think October 2019.                                                                                                                                                                                                                                                                                                     2\nName: count, Length: 720, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the most common comments with more than 10 words and more than 1 occurrence add the comment ID too\n",
    "all_repeated_comments = all_comments[all_comments[\"body\"].apply(lambda x: len(str(x).split()) >= 10)][\"body\"].value_counts()[all_comments[all_comments[\"body\"].apply(lambda x: len(str(x).split()) >= 10)][\"body\"].value_counts() > 1]\n",
    "all_repeated_comments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:51.503400Z",
     "start_time": "2024-04-02T13:00:49.713516Z"
    }
   },
   "id": "e05e93ec5dac0c34",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a6635b442f2d93c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:51.505422Z",
     "start_time": "2024-04-02T13:00:51.504013Z"
    }
   },
   "id": "821cab7c4a927e6d",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comments Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5dcdf29ece79cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the function to clean the comments\n",
    "def clean_comments(subreddits, min_word_count):\n",
    "    subreddits_data = {}\n",
    "    for subreddit_name in subreddits:\n",
    "        # Load the submissions and comments dataframes\n",
    "        submissions, comments = load_submissions_and_comments(subreddit_name)\n",
    "        # Add the submissions and comments dataframes to the dictionary\n",
    "        subreddits_data[subreddit_name] = {\"submissions\": submissions, \"comments\": comments}\n",
    "        \n",
    "    # Loop through the subreddits\n",
    "    for subreddit_name, data in subreddits_data.items():\n",
    "        initial_count = len(data[\"comments\"])\n",
    "\n",
    "        # Remove the comments that occur in all_repeated_comments and have more than 3 occurrences\n",
    "        data[\"comments\"] = data[\"comments\"][~data[\"comments\"][\"body\"].isin(all_repeated_comments[all_repeated_comments > 3].index)]\n",
    "        print(f\"{subreddit_name}: Removed {initial_count - len(data['comments'])} comments that occur in all_repeated_comments and have more than 3 occurrences\")\n",
    "        initial_count = len(data[\"comments\"])\n",
    "\n",
    "        # Clear the comments with less than min_word_count words\n",
    "        data[\"comments\"] = data[\"comments\"][data[\"comments\"][\"body\"].apply(lambda x: len(str(x).split()) >= min_word_count)]\n",
    "        print(f\"{subreddit_name}: Removed {initial_count - len(data['comments'])} comments with less than {min_word_count} words\")\n",
    "        initial_count = len(data[\"comments\"])\n",
    "\n",
    "        # Remove duplicated comments with same body and author\n",
    "        data[\"comments\"] = data[\"comments\"].drop_duplicates(subset=[\"body\", \"author\"])\n",
    "        print(f\"{subreddit_name}: Removed {initial_count - len(data['comments'])} duplicated comments\")\n",
    "        initial_count = len(data[\"comments\"])\n",
    "\n",
    "        # Remove comments with high percentage of special characters\n",
    "        data[\"comments\"] = data[\"comments\"][data[\"comments\"][\"body\"].apply(lambda x: len([c for c in str(x) if not c.isalnum()]) / len(str(x)) < 0.5)]\n",
    "        print(f\"{subreddit_name}: Removed {initial_count - len(data['comments'])} comments with high percentage of special characters\")\n",
    "\n",
    "        # Save the cleaned comments to a csv file\n",
    "        data[\"comments\"].to_csv(f'{data_directory}/{subreddit_name}/comments_cleaned_{min_word_count}.csv', index=False)\n",
    "\n",
    "        # Print the number of comments after cleaning\n",
    "        print(f\"{subreddit_name}: Number of comments after cleaning: {len(data['comments'])}\")\n",
    "        print()\n",
    "\n",
    "    # Print the total number of comments after cleaning\n",
    "    total_comments = sum([len(data[\"comments\"]) for data in subreddits_data.values()])\n",
    "    print(f\"Total number of comments after cleaning: {total_comments}\")\n",
    "\n",
    "    # Print the number of comments that were removed using\n",
    "    print(f\"Number of comments that were removed using all_comments: {len(all_comments) - total_comments}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:00:51.510098Z",
     "start_time": "2024-04-02T13:00:51.506036Z"
    }
   },
   "id": "68cc9dd88393d38c",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionPro: Removed 40 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "VisionPro: Removed 23764 comments with less than 10 words\n",
      "VisionPro: Removed 111 duplicated comments\n",
      "VisionPro: Removed 5 comments with high percentage of special characters\n",
      "VisionPro: Number of comments after cleaning: 58786\n",
      "\n",
      "virtualreality: Removed 156 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "virtualreality: Removed 44536 comments with less than 10 words\n",
      "virtualreality: Removed 107 duplicated comments\n",
      "virtualreality: Removed 11 comments with high percentage of special characters\n",
      "virtualreality: Number of comments after cleaning: 104832\n",
      "\n",
      "augmentedreality: Removed 8 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "augmentedreality: Removed 3819 comments with less than 10 words\n",
      "augmentedreality: Removed 18 duplicated comments\n",
      "augmentedreality: Removed 0 comments with high percentage of special characters\n",
      "augmentedreality: Number of comments after cleaning: 6314\n",
      "\n",
      "MetaQuestVR: Removed 35 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "MetaQuestVR: Removed 3351 comments with less than 10 words\n",
      "MetaQuestVR: Removed 15 duplicated comments\n",
      "MetaQuestVR: Removed 0 comments with high percentage of special characters\n",
      "MetaQuestVR: Number of comments after cleaning: 7668\n",
      "oculus: Removed 270 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "oculus: Removed 62405 comments with less than 10 words\n",
      "oculus: Removed 182 duplicated comments\n",
      "oculus: Removed 47 comments with high percentage of special characters\n",
      "oculus: Number of comments after cleaning: 132309\n",
      "\n",
      "OculusQuest: Removed 328 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "OculusQuest: Removed 65993 comments with less than 10 words\n",
      "OculusQuest: Removed 203 duplicated comments\n",
      "OculusQuest: Removed 24 comments with high percentage of special characters\n",
      "OculusQuest: Number of comments after cleaning: 120293\n",
      "\n",
      "Total number of comments after cleaning: 430202\n",
      "Number of comments that were removed using all_comments: 205428\n",
      "VisionPro: Removed 40 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "VisionPro: Removed 68544 comments with less than 50 words\n",
      "VisionPro: Removed 22 duplicated comments\n",
      "VisionPro: Removed 1 comments with high percentage of special characters\n",
      "VisionPro: Number of comments after cleaning: 14099\n",
      "\n",
      "virtualreality: Removed 156 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "virtualreality: Removed 124179 comments with less than 50 words\n",
      "virtualreality: Removed 17 duplicated comments\n",
      "virtualreality: Removed 0 comments with high percentage of special characters\n",
      "virtualreality: Number of comments after cleaning: 25290\n",
      "\n",
      "augmentedreality: Removed 8 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "augmentedreality: Removed 8765 comments with less than 50 words\n",
      "augmentedreality: Removed 4 duplicated comments\n",
      "augmentedreality: Removed 0 comments with high percentage of special characters\n",
      "augmentedreality: Number of comments after cleaning: 1382\n",
      "\n",
      "MetaQuestVR: Removed 35 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "MetaQuestVR: Removed 9226 comments with less than 50 words\n",
      "MetaQuestVR: Removed 4 duplicated comments\n",
      "MetaQuestVR: Removed 0 comments with high percentage of special characters\n",
      "MetaQuestVR: Number of comments after cleaning: 1804\n",
      "\n",
      "oculus: Removed 270 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "oculus: Removed 166164 comments with less than 50 words\n",
      "oculus: Removed 46 duplicated comments\n",
      "oculus: Removed 3 comments with high percentage of special characters\n",
      "oculus: Number of comments after cleaning: 28730\n",
      "\n",
      "OculusQuest: Removed 328 comments that occur in all_repeated_comments and have more than 3 occurrences\n",
      "OculusQuest: Removed 163622 comments with less than 50 words\n",
      "OculusQuest: Removed 34 duplicated comments\n",
      "OculusQuest: Removed 2 comments with high percentage of special characters\n",
      "OculusQuest: Number of comments after cleaning: 22855\n",
      "\n",
      "Total number of comments after cleaning: 94160\n",
      "Number of comments that were removed using all_comments: 541470\n"
     ]
    }
   ],
   "source": [
    "# Clean the comments for all subreddits\n",
    "\n",
    "# Clean with min_word_count = 10\n",
    "clean_comments(subreddits, 10)\n",
    "# Clean with min_word_count = 50\n",
    "clean_comments(subreddits, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:01:07.120765Z",
     "start_time": "2024-04-02T13:00:51.510640Z"
    }
   },
   "id": "ecad2069aa26b6a5",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionPro: Number of cleaned comments: 14099\n",
      "virtualreality: Number of cleaned comments: 25290\n",
      "augmentedreality: Number of cleaned comments: 1382\n",
      "MetaQuestVR: Number of cleaned comments: 1804\n",
      "oculus: Number of cleaned comments: 28730\n",
      "OculusQuest: Number of cleaned comments: 22855\n"
     ]
    }
   ],
   "source": [
    "# Combine the cleaned comments for all subreddits\n",
    "cleaned_comments_list = []\n",
    "min_word_count = 50\n",
    "for subreddit_name in subreddits:\n",
    "    # Load the cleaned comments\n",
    "    cleaned_comments = pd.read_csv(f'{data_directory}/{subreddit_name}/comments_cleaned_{min_word_count}.csv')\n",
    "    # Add the subreddit name to the cleaned comments\n",
    "    cleaned_comments[\"subreddit\"] = subreddit_name\n",
    "    # Add the cleaned comments to the list\n",
    "    cleaned_comments_list.append(cleaned_comments)\n",
    "\n",
    "# Concatenate all the cleaned comments into a single DataFrame\n",
    "all_cleaned_comments = pd.concat(cleaned_comments_list)\n",
    "\n",
    "# Save the cleaned comments to a csv file\n",
    "all_cleaned_comments.to_csv(f'{data_directory}/all/comments_cleaned_{min_word_count}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:01:44.955579Z",
     "start_time": "2024-04-02T13:01:42.420522Z"
    }
   },
   "id": "1367d711a9fb9bc2",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "94160"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned comments for all subreddits\n",
    "cleaned_comments = pd.read_csv(f'{data_directory}/all/comments_cleaned_{min_word_count}.csv')\n",
    "\n",
    "# Print the number of comments \n",
    "len(cleaned_comments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:01:49.242922Z",
     "start_time": "2024-04-02T13:01:48.033047Z"
    }
   },
   "id": "340b70b1f78479dd",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
